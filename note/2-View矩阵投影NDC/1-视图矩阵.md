**视图矩阵**

如何将世界空间中的坐标渲染到屏幕空间

将世界空间中的坐标渲染到屏幕空间需要经过以下几个步骤：

1. 将物体的顶点从世界坐标系转换为观察坐标系。

这可以通过将模型矩阵乘以视图矩阵来实现。模型矩阵将物体从模型空间转换到世界空间，而视图矩阵将场景从世界空间转换到观察空间。最终结果是将物体从模型空间转换到观察空间。

2. 将观察坐标系中的坐标投影到裁剪空间。

这可以通过将观察坐标系中的坐标乘以投影矩阵来实现。投影矩阵定义了一个透视框，可以将观察坐标系中的坐标映射到裁剪空间中。

3. 将裁剪空间中的坐标转换为标准化设备坐标。

这可以通过将裁剪空间中的坐标除以其w分量来实现。这将使每个坐标的范围从[-w, w]变为[-1, 1]。

4. 将标准化设备坐标转换为屏幕空间。

这可以通过将坐标映射到屏幕上的像素位置来实现。通常，这涉及到确定视口（Viewport）的大小和位置，并使用它来将标准化设备坐标转换为像素坐标。

在完成这些步骤后，您就可以将世界空间中的坐标渲染到屏幕空间中。这些步骤通常由图形管线中的顶点着色器和投影矩阵执行。



射线选取原理，将屏幕空间的点映射到NDC空间，再从NDC空间转换到对象空间

OpenGL

下图是OpenGL里的屏幕坐标，坐标原点在屏幕中心。u（y)轴假定为1，那么v（x）轴就为ar和-ar

![image-20231228112404865](.\image-20231228112404865.png)

![image-20231228112705362](.\image-20231228112705362.png)
$$
DirectX\\ \\
M = 
\begin{bmatrix}
\frac{1}{ar * \tan{\frac{a}{2}}} & 0 & 0 & 0\\
0 & \frac{1}{\tan{\frac{a}{2}}} & 0 & 0\\
0 & 0 & \frac{NearZ+FarZ}{FarZ-NearZ} & \frac{2*FarZ*NearZ}{NearZ - FarZ}\\
0 & 0 & -1 & 0
\end{bmatrix}

\\ \\ OpenGL\\ \\
\begin{bmatrix}
\frac{1}{ar * \tan{\frac{a}{2}}} & 0 & 0 & 0\\
0 & \frac{1}{\tan{\frac{a}{2}}} & 0 & 0\\
0 & 0 & \frac{NearZ+FarZ}{FarZ-NearZ} & \frac{2*FarZ*NearZ}{NearZ - FarZ}\\
0 & 0 & 1 & 0
\end{bmatrix}
$$





$$
DirectX\\
\\
M =
\begin{bmatrix}
\frac{2n}{r-l} & 0 & \frac{r+l}{r-l} & 0 \\
0 & \frac{2n}{t-b} & \frac{t+b}{t-b} & 0\\
0 & 0 & -\frac{f+n}{f-n} & -\frac{2fn}{f-n}\\
0 & 0 & -1 & 0
\end{bmatrix}


\\ \\ OpenGL\\
\\
M =
\begin{bmatrix}
\frac{2n}{r-l} & 0 & \frac{r+l}{r-l} & 0 \\
0 & \frac{2n}{t-b} & \frac{t+b}{t-b} & 0\\
0 & 0 & -\frac{f+n}{f-n} & -\frac{2fn}{f-n}\\
0 & 0 & 1 & 0
\end{bmatrix}
$$


# 容易混淆的Clip Space vs NDC，透视除法

剪裁空间（Clip Space）和标准化设备坐标（NDC）

Clip Space是一个顶点乘以MVP矩阵之后所在的空间，**Vertex Shader的输出就是在Clip Space上**（划重点），接着由GPU自己做**透视除法**将顶点转到NDC。

透视除法将Clip Space顶点的4个分量都除以w分量，就从Clip Space转换到了NDC了。

而NDC是一个长宽高取值范围为[-1,1]的立方体，超过这个范围的顶点，会被GPU剪裁。



![img](https://pic4.zhimg.com/80/v2-4baca450c51c7f0eea873c42eeda0eef_720w.webp)



**注**：在DirectX里面，NDC的z方向取值范围是[0,1]，在Unity中可以用`UNITY_NEAR_CLIP_VALUE`获取z方向近平面的值，在openGL环境下是-1.0，DirectX中是0.0。

**这里以OpenGL坐标系为准，D3D坐标系会有一些差异，见**[[1\]](https://zhuanlan.zhihu.com/p/65969162#ref_1)。



我们假设在NDC中剪裁后的点的坐标为(x',y',z',1)，那x‘、y'和z'的取值范围都在[-1,1]，那么反推回去Clip Space上的点就是：
$$
p = (x'，y',z')*w = (wx',wy',wz')
$$


其中w = -z，这个z是顶点在View Space中的z值（为了满足投影性质推导出来的值，见下方资料，这里负号因为推导用的View Space是右手坐标系，NDC是左手坐标系）。所以显然，Clip Space的取值范围和NDC是不一样的。



至于为什么这整个过程是这样的，有一些图形学或数学书有讲到推导过程，如《Mathematics for 3D Game Programming and Computer Graphics》，或者这篇文章[[2\]](https://zhuanlan.zhihu.com/p/65969162#ref_2)。如果不知道数学过程也没关系，只要记住**Vertex Shader的输出在Clip Space，然后GPU自己做透视除法变到了NDC（取值范围[-1,1]）**。



### **Fragment Shader的输入是在什么空间？**

Vertex Shader的输出在Clip Space，那Fragment Shader的输入在什么空间？不是NDC，而是**屏幕空间Screen Space**。

我们前面说到Vertex Shader的输出在Clip Space，接着GPU会做透视除法变到NDC。这之后GPU还有一步，应用视口变换，转换到Window Space(Screen Space)，输入给Fragment Shader：



**(Vertex Shader) => Clip Space => (透视除法) => NDC => (视口变换) => Window Space => (Fragment Shader)**



视口变换的计算方法也很简单，假设视口的原点为(x,y)，长宽为(width,height)。

以x轴为例，变换只是将NDC的[-1,1] 线性映射到[x, x+width]范围内。

z轴则会从NDC的[-1,1]映射到[nearVal, farVal]内（默认near=0，far=1）。

width, height, near, far 等参数可以通过如下函数指定：

```c
void glViewport(GLint *x*, GLint *y*, GLsizei *width*, GLsizei *height*);
void glDepthRangef(GLfloat *nearVal*, GLfloat *farVal*);
```

此线性映射关系容易写出转换公式如下：

![img](https://pic1.zhimg.com/80/v2-2e155c10c9d02c71466d22d0a8b84e5c_720w.webp)



### **SV_Position和gl_FragCoord的w分量**

前面提到了Fragment Shader的输入是经过视口变换后的坐标，Shader中访问的方法是：OpenGL中通过gl_FragCoord来访问，D3D中则通过SV_Position语义访问。

此输入参数的xy分量表示Screen Space的坐标，z表示写入到深度缓冲中的值，那么w分量表示什么呢？

透视除法的时候，(x,y,z,w) => (x/w, y/w, z/w, w/w)。会发现最后一个分量变成了1没什么意义，所以不如存点有用的数据，对于SV_Position来说，最后一个分量存的就是w，也即View Space的Z。

对于gl_FragCoord来说，存的是1/w[[3\]](https://zhuanlan.zhihu.com/p/65969162#ref_3)。